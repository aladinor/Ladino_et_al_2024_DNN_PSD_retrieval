{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5beb277-bc6f-4bff-89ad-69dc059291de",
   "metadata": {},
   "source": [
    "# K-Means clutering technique to find PSD families within the CAMP2Ex field campain dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a025d9-83db-4c93-a0c0-bb7dfd46ad0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af2107b-6693-46d5-848b-c7c1120e07cc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406855a6-b204-4360-812c-afac39aaf8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import datatree\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.transforms as mtransforms\n",
    "from xhistogram.xarray import histogram\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "from scipy.special import gamma\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81b558-2d1d-4517-8add-56154d33b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the Seaborne style including figure  dpi\n",
    "sns.set(rc={\"figure.dpi\":150, 'savefig.dpi':150})\n",
    "sns.set(style='white', font_scale=0.9)\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a7d39-e3f0-43e9-83af-031d09f241b7",
   "metadata": {},
   "source": [
    "### Local Cluster\n",
    "\n",
    "Let's spin up our `Dask` local cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753574c-2935-430a-b5db-127a1a11a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster()  \n",
    "# display(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9641d-f02e-4b69-b1ea-4d410fe78b49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data\n",
    "\n",
    "CAMP2Ex dataset is store in Analysis-Ready Cloud-Optimized (ARCO) format ([Abernathey et al. 2021](https://ieeexplore.ieee.org/document/9354557)) using [Xarray-Datatree](https://xarray-datatree.readthedocs.io/en/latest/) data model that allows us to have both Learjet and P3B datasets in one `datatree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567caca4-89e3-4cd1-8824-00231463e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/camp2ex_dtree.zarr'\n",
    "dt_camp2ex = datatree.open_datatree(path_data, engine='zarr', consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6fc586-29f4-46a1-b27e-15ccce5a783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dt_camp2ex['Lear'].ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a986f-5e46-4823-87dc-ff2e689227d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(dt_camp2ex['P3B'].ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f4947e-be7b-4f57-966c-95a62d07d1a0",
   "metadata": {},
   "source": [
    "Let's select the following fields we will use during the K-means clustering analysis and other variables we will use during our Deep Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5a57c-c3af-4734-b5db-336fdd8a96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sigma', 'dm', 'log10_nw', 'r', 'nt', 'lwc_cum', 'dbz_t_ku', 'dbz_t_ka', 'mu', 'new_mu', 'Att_ka', 'temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1026bcf-e5fa-4b24-9c9b-3297cb39f263",
   "metadata": {},
   "source": [
    "Now we can merge both datasets into a single `Xarray.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78289612-93f6-4eb6-9aca-a5ef9294e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.concat([dt_camp2ex['Lear'].ds[cols], dt_camp2ex['P3B'].ds[cols]], dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49e98a-c2b2-49e3-8d4a-06e09d30dbca",
   "metadata": {},
   "source": [
    "We discarded data with Liquid Water Content  $LWC <=0.01 gm^{-3}$ (Lance et at., 2010, Gupta et al 2021) and take $log_{10}$ of rainfall rate (r), total number concentration (nt) and liquid water content (lwc_cum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5668652-47bd-4f6e-aea9-079b60d31f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.where(ds.lwc_cum > 0.01, drop=True)\n",
    "ds = ds\n",
    "ds['logr'] = np.log10(ds.r)\n",
    "ds['lognt'] = np.log10(ds.nt)\n",
    "ds['loglwc'] = np.log10(ds.lwc_cum)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99fb7e1-3091-4f92-b12d-fae1f21b7748",
   "metadata": {},
   "source": [
    "Now we converted our `Xarray.Dataset` into a `Panda.Dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4caf713-6647-4f53-bf8e-d6b1d62c7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_dataframe().reset_index()\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8753fa-a06b-4181-8bfd-2101a3174542",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "To apply the cluster analysis, we standardized our input features by removing the mean and scaling to unit variance using the [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) from the `Sklearn` Python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f06d4-57ee-4b18-a30e-71634ca180a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['sigma_T', 'dm_T', 'log10_nw_T', 'logr_T', 'lognt_T', \"loglwc_T\"]]= scaler.fit_transform(df[['sigma', 'dm', 'log10_nw', 'logr', 'lognt', 'loglwc']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a495de3-ac2f-4fd9-85cd-ae0216eff7e7",
   "metadata": {},
   "source": [
    "### K-means clustering benchmarking\n",
    "\n",
    "As a supervised machine learning technique, K-means clustering requires the number of the cluster to be defined beforehand. To determine the optimal number of clusters (k) for the PSDs, we executed the algorithm for k values ranging from 2 to 15. Using the within-cluster sum of squares (WCSS), also known as the elbow method, Davies-Bouldin index (Davies & Bouldin, 1979), and Silhouette score (Rousseeuw, 1987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e3d8f9-56eb-44dc-b420-1b87ec07d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_score(df, center):\n",
    "    '''\n",
    "    returns the elbow inertial index, the Davies Bouldin and Silhouette score\n",
    "    INPUT:\n",
    "        data - the dataset you want to fit kmeans to\n",
    "        center - the number of centers you want (the k value)\n",
    "    OUTPUT:\n",
    "        elbow inertial index, the Davies Bouldin and Silhouette score\n",
    "    '''\n",
    "    kmeans = KMeans(n_clusters=center, random_state=10)\n",
    "    model = kmeans.fit(df)\n",
    "    model2 = kmeans.fit_predict(df)\n",
    "    cluster_labels = model.labels_\n",
    "    \n",
    "    dav = davies_bouldin_score(df, model2)\n",
    "    sil = silhouette_score(df, cluster_labels)\n",
    "    elbow = model.inertia_\n",
    "    return dav, sil, elbow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c137765-157a-483a-9fd8-66d13150da24",
   "metadata": {},
   "source": [
    "We defined some list to store results of each cluster results for every score. Then we test each number of cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bf49b-5103-4250-a489-817d4fded65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dav = []\n",
    "sil = []\n",
    "elbow = []\n",
    "\n",
    "for k in range(2,15):\n",
    "    _dav, _sil, _el = get_kmeans_score(df[['sigma_T', 'dm_T', 'log10_nw_T', 'logr_T', 'lognt_T', \"loglwc_T\"]], k)\n",
    "    dav.append(_dav)\n",
    "    sil.append(_sil)\n",
    "    elbow.append(_el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83acd248-45d2-436a-a557-a9a3fbfcfabf",
   "metadata": {},
   "source": [
    "Now, we can see the score result for different number of clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba3ee2a-1600-4937-88f1-495d858f6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = range(2,15)\n",
    "fig, (ax, ax1, ax2) = plt.subplots(1, 3, figsize=(12, 4), dpi=100)\n",
    "ax.plot(centers, dav, linestyle='--', marker='o', color='b');\n",
    "ax.set_xlabel('K');\n",
    "ax.set_ylabel('Score');\n",
    "ax.set_title('Davies Bouldin method');\n",
    "\n",
    "ax1.plot(centers, sil, linestyle='--', marker='o', color='b');\n",
    "ax1.set_xlabel('K');\n",
    "ax1.set_ylabel('Score');\n",
    "ax1.set_title('silhouette method');\n",
    "\n",
    "ax2.plot(centers, elbow, linestyle='--', marker='o', color='b');\n",
    "ax2.set_xlabel('K');\n",
    "ax2.set_ylabel('Score');\n",
    "ax2.set_title('Elbow method');\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7758d83-e225-455c-8315-b62fe4bdf9c5",
   "metadata": {},
   "source": [
    "### K-means clustering with 6 PSD families\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ba502-c488-4447-8a03-8515ab4acd71",
   "metadata": {},
   "source": [
    "Based on the cluster benchmarking, we deduced that k=6 the most suitable number of clusters representing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f67b9-4121-43b5-b83d-18b24194958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select scaled/transformed data\n",
    "X = df[['sigma_T', 'dm_T', 'log10_nw_T', 'logr_T', 'lognt_T', \"loglwc_T\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cef7f86-81f1-4318-bdc5-162643d39c37",
   "metadata": {},
   "source": [
    "We can now apply the K-means cluster technique using these (X) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e3e9e-2a78-4ca9-a1c6-0018b24df8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=10)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b23ecbf-1a63-4696-bc7a-e9a493f65e58",
   "metadata": {},
   "source": [
    "Create a new column with the Kmeans labels. We add one to have labales from 1 to 6 (instead of 0 to 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac7a24a-1aae-4062-98de-c2773cefd504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kmeans_6'] = kmeans.labels_ + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306645f-b01c-457c-8e8b-7014637beec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder and replace some labels to make them equal when plotting mean PSDs\n",
    "df['kmeans'] = df['kmeans_6'].replace([6, 1, 5, 2, 4, 3], \n",
    "                                      [1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# computing Dual Frequency Ratio\n",
    "df['dfr'] = df['dbz_t_ku'] - df['dbz_t_ka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dddd91e-3d9a-49c0-acd4-774edf9f1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that computes the Normalized-Gama size distribution\n",
    "def norm_gamma(d, nw, mu, dm):\n",
    "    \"\"\"\n",
    "    Functions that computes the normalized-gamma size distritubion (Testud et al., 2002)\n",
    "    Param d: diameter in mm\n",
    "    Param nw: Normalized intercep parameter\n",
    "    Param mu: Shape parameter\n",
    "    Param dm: Mass-weighted mean diameter\n",
    "    \"\"\"\n",
    "    f_mu = (6 * (4 + mu) ** (mu + 4)) / (4 ** 4 * gamma(mu + 4) )\n",
    "    slope = (4 + mu) / dm\n",
    "    return nw * f_mu * (d / dm) ** mu * np.exp(-slope * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2eba5-6120-45ed-9927-e43b1c5e62ee",
   "metadata": {},
   "source": [
    "### K-means results \n",
    "\n",
    "Scatter plot of Dm and Nw colored by each PSD family is plotted as following. Mean PSD computed using the mean quantities of each parameter at each group is also displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477bae1-bf80-4e68-9738-f5090a4dbbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of clusters\n",
    "n_c = 6\n",
    "# defining the Colormap for each cluster identified\n",
    "my_cmap6 = ListedColormap(sns.color_palette('deep', n_c))\n",
    "colors6 = my_cmap6(np.linspace(0,1, n_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203c5dc-6d91-453a-a193-b1bbde4f7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results \n",
    "fig, axs = plt.subplot_mosaic([['a)', 'b)']], figsize=(8,4))\n",
    "\n",
    "# left panel\n",
    "ax = axs['a)']\n",
    "# Scatter plot of Dm and Nw\n",
    "ax = sns.scatterplot(data=df, x=df['dm'], y=df['log10_nw'], hue=df['kmeans'], s=3, ax=ax, \n",
    "                          palette=sns.color_palette('deep', 6), legend=False, edgecolor=None)\n",
    "\n",
    "ax.set_xlabel(\"$D_m \\ [mm]$\")\n",
    "ax.set_ylabel(\"$Log_{10}(Nw) \\ [Log_{10}(mm^{1}mm^{-3})]$\")\n",
    "ax.grid('both', linestyle='--', lw=0.5, dashes=[7,7])\n",
    "\n",
    "dms = np.linspace(df['dm'].min(), df['dm'].max(), 100)\n",
    "\n",
    "# Plotting Bringi et al (2009) convective-stratiform separation\n",
    "s_c = -1.6 * dms + 6.3\n",
    "ax.plot(dms, s_c, c='k', ls='-.', lw=0.8, label=r\"$Bringi \\ et \\ al. \\ (2009)$\")\n",
    "ax.legend()\n",
    "\n",
    "# right panel\n",
    "ax1 = axs['b)']\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(1e-3, 1e9)\n",
    "d = dt_camp2ex['Lear'].ds.diameter/1000\n",
    "ax1.grid('both')\n",
    "ax1.set_ylabel(\"$N(D) \\  [mm^{-1}m^{-3}]$\")\n",
    "ax1.set_xlabel(\"$D\\ [mm]$\")\n",
    "ax1.grid('both', linestyle='--', lw=0.5, dashes=[7,7])\n",
    "ax1.set_xlim(-0.2, 3)\n",
    "\n",
    "# computing the mean particle size distribution for each group\n",
    "for i in range(1, n_c + 1):\n",
    "    df_sub = df[df['kmeans'] == i]\n",
    "    mu = df_sub['mu'].quantile(0.5)\n",
    "    dm = df_sub['dm'].quantile(0.5)\n",
    "    nw = (10 ** (df_sub['log10_nw'])).quantile(0.5)\n",
    "    gm = norm_gamma(d, nw=nw, mu=mu, dm=dm)\n",
    "    ax1.plot(d, gm, c=colors6[i-1], label=f\"Group {i}\")\n",
    "\n",
    "\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "\n",
    "\n",
    "fig.legend(lines[1:], labels[1:], loc='upper center', ncol=6, bbox_to_anchor=[0.5, 1.025])\n",
    "for label, ax in axs.items():\n",
    "    # label physical distance in and down:\n",
    "    trans = mtransforms.ScaledTranslation(-45/72, -1/72, fig.dpi_scale_trans)\n",
    "    ax.text(0.0, 1.0, label, transform=ax.transAxes + trans,\n",
    "            fontsize='medium', verticalalignment='top')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420a2b6f-6e36-4084-89d1-ab88637f6a18",
   "metadata": {},
   "source": [
    "## Dataset Imbalance\n",
    "\n",
    "It is safe to check data imbalance before performing a machine learning algorithm. We set a $1 mm$ treshold in $D_m$ for counting the number of PSDs within each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf337f-9604-49d4-9c21-b4ccc9a91973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a categorical variable to split data into greater and smaller Dm\n",
    "df['dm_class'] = (df.dm >= 1.0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380df9a5-56c8-43f8-91a8-fd5f066ee7ff",
   "metadata": {},
   "source": [
    "Then, we can create a two-dimension histogram to see the density distribution of our dataset. Also, we can include a bar diagram with the two classess we previously defined ($D_m >= 1mm$ and $D_m < 1mm$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd137ac6-27e6-4d6b-8354-1bfc966db506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the 2D-histogram inputs\n",
    "xbins = np.linspace(ds.dm.min(), ds.dm.max(), 50)\n",
    "ybins = np.linspace(ds.log10_nw.min(), ds.log10_nw.max(), 50)\n",
    "psd = histogram(ds.dm, ds.log10_nw, bins=[xbins, ybins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4812055-fb05-4221-9524-1886e87360c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting data imbalance results\n",
    "fig, ax = plt.subplots(figsize=(5.5,4.5))\n",
    "\n",
    "# 2D-histogram\n",
    "im = psd.T.where(psd.T > 0, np.nan).plot(add_colorbar=False, ax=ax, cmap='magma_r', vmin=0, vmax=100)\n",
    "fig.colorbar(im , ax=ax, label=r\"$Counts$\")\n",
    "ax.set_xlabel(\"$D_m \\ [mm]$\")\n",
    "ax.set_ylabel(\"$Log_{10}(Nw) \\ [Log_{10}(mm^{1}mm^{-3})]$\")\n",
    "sns.despine()\n",
    "ax.grid('both', linestyle='--', lw=0.5, dashes=[7,7])\n",
    "ax.set_xlim(-0.1, 2.8)\n",
    "ax.set_ylim(2, 11)\n",
    "ax.vlines(x=1, ymin=2, ymax=11, lw=0.5, linestyle='--', color='k')\n",
    "\n",
    "# Bar plot\n",
    "l, b, h, w = .45, .60, .15, .3\n",
    "ax2 = fig.add_axes([l, b, w, h])\n",
    "bar_colors = ['tab:red', 'tab:blue']\n",
    "ax2.bar(['$D_m < 1.0$', \"$D_m \\geq 1.0$\"], np.bincount(df['dm_class']), color=bar_colors)\n",
    "ax2.set_title(\"Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661e28f-5dbf-4a16-ab23-3a2184ee1501",
   "metadata": {},
   "source": [
    "### Saving dataframe\n",
    "\n",
    "We saved the Kmeans output and dataset imbalance results for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafcb7c8-c373-4651-914a-67de48d52639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../data/df_cluster.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
